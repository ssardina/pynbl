{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyNBL: Basketball Statistic System for Australian NBL\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ssardina/pynbl/HEAD)\n",
    "\n",
    "This notebook **incrementally** builds a set of stat tables from NBL Basketball Games:\n",
    "\n",
    "1. A table of games played, with team names, points, venue, etc.\n",
    "2. A stat table of _stint lineups_ (advance) statistics for each game and each team. A **stint** is a lineup of players who play together in different interval periods across the game. This table will contain the stints for each team from the play-by-play data and compute various statistics for those stints.\n",
    "\n",
    "Tables will be saved in CSV and Excel formats as well as in [Pickle format](https://docs.python.org/3/library/pickle.html) for later recovery as Panda DataFrames.\n",
    "\n",
    "\n",
    "The data comes as a raw JSON file using the game id (e.g., `2087737`):\n",
    "\n",
    "https://fibalivestats.dcd.shared.geniussports.com/data/2087737/data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load all required packages...\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dtale\n",
    "\n",
    "from nbl.config import *\n",
    "from nbl import bball_stats, tools\n",
    "\n",
    "\n",
    "# Set folder with data files and Pickle tables saved on disk\n",
    "def get_save_files(dir):\n",
    "    FILES = dict()\n",
    "    FILES['stint_stats'] = Path(dir, \"stint_stats_df\").with_suffix('.pkl')\n",
    "    FILES['stints'] = Path(dir, \"stints_df\").with_suffix('.pkl')\n",
    "    FILES['games'] = Path(dir, \"games_df\").with_suffix('.pkl')\n",
    "    FILES['players'] = Path(dir, \"players_df\").with_suffix('.pkl')\n",
    "\n",
    "    return FILES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "First, setup the games we want to scrape and compute, as well as the existing data stored in file to append to.\n",
    "\n",
    "**Note:** This should be the only section requiring modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games to scrape (179): [('2120056', 0), ('2122059', 0), ('2134935', 0), ('2120058', 0), ('2120079', 0), ('2124207', 0), ('2116576', 0), ('2120054', 0), ('2120077', 0), ('2141127', 0), ('2120052', 0), ('2120055', 0), ('2122060', 0), ('2141126', 0), ('2120057', 0), ('2135116', 0), ('2135117', 0), ('2120080', 0), ('2120051', 0), ('2116579', 0), ('2120049', 0), ('2120050', 0), ('2120078', 0), ('2120048', 0), ('2120053', 0), ('2116412', 1), ('2116391', 1), ('2116406', 1), ('2116390', 1), ('2116402', 1), ('2116381', 2), ('2116379', 2), ('2116429', 2), ('2116437', 2), ('2116420', 2), ('2116436', 2), ('2116423', 2), ('2116435', 2), ('2116384', 3), ('2116518', 3), ('2116419', 3), ('2116422', 3), ('2116386', 3), ('2116385', 3), ('2116407', 3), ('2116413', 3), ('2116378', 4), ('2116389', 4), ('2116380', 4), ('2116382', 4), ('2116388', 4), ('2116387', 4), ('2116383', 4), ('2116411', 4), ('2116396', 5), ('2116417', 5), ('2116408', 5), ('2116414', 5), ('2116403', 5), ('2116393', 5), ('2116418', 5), ('2116400', 5), ('2116394', 6), ('2116424', 6), ('2116421', 6), ('2116401', 6), ('2116430', 6), ('2116432', 6), ('2116398', 6), ('2116427', 7), ('2116434', 7), ('2116410', 7), ('2116428', 7), ('2116433', 7), ('2116416', 7), ('2116405', 7), ('2116409', 8), ('2116397', 8), ('2116404', 8), ('2116395', 8), ('2116415', 8), ('2116399', 8), ('2116426', 9), ('2116438', 9), ('2116431', 9), ('2116455', 9), ('2116425', 9), ('2116454', 9), ('2116448', 9), ('2116443', 9), ('2116486', 10), ('2116444', 10), ('2116463', 10), ('2116473', 10), ('2116487', 10), ('2116439', 10), ('2116468', 10), ('2116478', 10), ('2116469', 11), ('2116456', 11), ('2116459', 11), ('2116449', 11), ('2116483', 11), ('2116482', 11), ('2116440', 11), ('2116475', 11), ('2116445', 11), ('2116453', 12), ('2116471', 12), ('2116450', 12), ('2116480', 12), ('2116467', 12), ('2116477', 12), ('2116462', 12), ('2116447', 13), ('2116442', 13), ('2116465', 13), ('2116452', 13), ('2116458', 13), ('2116460', 13), ('2224808', 13), ('2116441', 14), ('2116446', 14), ('2116474', 14), ('2116457', 14), ('2116484', 14), ('2116479', 14), ('2116470', 14), ('2116451', 14), ('2116481', 15), ('2116488', 15), ('2116466', 15), ('2116492', 15), ('2116472', 15), ('2116476', 15), ('2116489', 15), ('2116491', 15), ('2116490', 15), ('2116461', 15), ('2223754', 15), ('2116505', 16), ('2116493', 16), ('2116495', 16), ('2116500', 16), ('2116497', 16), ('2116496', 16), ('2116494', 16), ('2116498', 16), ('2116502', 16), ('2116508', 17), ('2116510', 17), ('2116499', 17), ('2116514', 17), ('2116506', 17), ('2116516', 17), ('2116512', 17), ('2116517', 17), ('2116501', 17), ('2116504', 18), ('2116507', 18), ('2116513', 18), ('2116511', 18), ('2116503', 18), ('2116515', 18), ('2116509', 18), ('2238356', 101), ('2238362', 101), ('2238360', 101), ('2241870', 101), ('2241866', 101), ('2241869', 101), ('2238361', 101), ('2241867', 101), ('2237135', 101), ('2241868', 101), ('2238359', 101), ('2237136', 101), ('2238357', 101), ('2238358', 101)]\n",
      "Rounds:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 101]\n",
      "First round: 0 - Last round: 101\n",
      "Folder to be used: data/2022-23\n",
      "Reload games? False\n"
     ]
    }
   ],
   "source": [
    "# Games to be computed  - Format: (game id, round number)\n",
    "from games_22_23 import GAMES\n",
    "\n",
    "DATA_DIR = 'data/2022-23'\n",
    "# DATA_DIR = 'data/2023-24'\n",
    "\n",
    "# sort games by rounds (second component of tuple) and get min/max rounds\n",
    "GAMES.sort(key = lambda x: x[1])\n",
    "ROUNDS = list(set([g[1] for g in GAMES]))\n",
    "FIRST_ROUND = min(ROUNDS)\n",
    "LAST_ROUND = max(ROUNDS)\n",
    "\n",
    "games_issues = [('2031329', 0)  # https://github.com/ssardina/pynbl/issues/1\n",
    "         ]\n",
    "# DATA_DIR, games = 'test/', games_issues\n",
    "\n",
    "# Set to True to re-compute from scratch all tables\n",
    "reload = False\n",
    "\n",
    "print(f\"Games to scrape ({len(GAMES)}):\", GAMES)\n",
    "print(f\"Rounds: \", ROUNDS)\n",
    "print(f\"First round: {FIRST_ROUND} - Last round: {LAST_ROUND}\")\n",
    "print(\"Folder to be used:\", DATA_DIR)\n",
    "print(\"Reload games?\", reload)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute stat and game tables\n",
    "\n",
    "Now, let us run the system that scrapes the games' data, computes stats and game info, and adds them to the initial tables of stats and games.\n",
    "\n",
    "We start by loading all saved previous games, if any, as we want to append to that database (and we don't want to recompute them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables from saved files (if any)\n",
    "saved_stint_stats_df = None\n",
    "saved_stints_df = None\n",
    "saved_games_df = None\n",
    "saved_players_df = None\n",
    "existing_games = []\n",
    "\n",
    "FILES = get_save_files(DATA_DIR)\n",
    "\n",
    "if not reload:\n",
    "    # load the stat dataframe already stored as a file\n",
    "    print(f\"Loading recorded dataframes from files\")\n",
    "    try:\n",
    "        saved_stint_stats_df = pd.read_pickle(FILES['stint_stats'])\n",
    "        saved_stints_df = pd.read_pickle(FILES['stints'])\n",
    "        saved_games_df = pd.read_pickle(FILES['games'])\n",
    "        saved_players_df = pd.read_pickle(FILES['players'])\n",
    "        # collect game ids of all games recovered from file\n",
    "        existing_games = saved_games_df.game_id.unique()\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Error loading Pickle files: \", e)\n",
    "        saved_stint_stats_df = None\n",
    "        saved_stints_df = None\n",
    "        saved_games_df = None\n",
    "        saved_players_df = None\n",
    "        existing_games = []\n",
    "else:\n",
    "    existing_games = []\n",
    "\n",
    "print(f\"Recovered {len(existing_games)} games: \", existing_games)\n",
    "\n",
    "# saved_stats_df['lineup'].apply(lambda x: len(x) > 5)\n",
    "# saved_stats_df.loc[5,'lineup']\n",
    "# saved_stats_df.loc[5]\n",
    "\n",
    "# saved_stint_stats_df.sample(3)\n",
    "# saved_games_df.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to process games to extract:\n",
    "\n",
    "1. Table of **games**.\n",
    "2. Table of **players** who played in each game with their stats, for each team.\n",
    "3. Table of **stints** in each game for each team.\n",
    "4. Table of **stint stats** in each game for each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect here set of stat dfs and game info, one per game\n",
    "#   then, we will put them together into different dataframes\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "stint_stats_dfs = []\n",
    "stints_dfs = []\n",
    "players_dfs = []\n",
    "games_data = []\n",
    "\n",
    "# Build data for each game, we'll put them together after....\n",
    "for game in GAMES:\n",
    "    # game is beyond the last round available, stop processing..\n",
    "    if game[1] > LAST_ROUND:\n",
    "        break\n",
    "\n",
    "    # get game_id and round no (if available)\n",
    "    if isinstance(game, tuple):\n",
    "        game_id, round_no = game\n",
    "    else:\n",
    "        game_id = game\n",
    "        round_no = np.nan # no round info available\n",
    "\n",
    "    # don't scrape game data if already loaded from file, skip it\n",
    "    if game_id in existing_games:\n",
    "        print(f\"Game {game_id} was already saved on file; no scrapping...\")\n",
    "        continue\n",
    "\n",
    "    ##################################################################\n",
    "    # !!! MAIN STEP: scrape and compute the actual stats for the game\n",
    "    ##################################################################\n",
    "    print(f\"Computing game {game_id} (round {round_no})...\")\n",
    "\n",
    "    # 1. Read game JSON file\n",
    "    try:\n",
    "        game_json = tools.get_json_data(game_id, dir=DATA_DIR)\n",
    "    except (HTTPError, ValueError) as e:\n",
    "        LAST_ROUND = round_no    # this is the last round to be processed!\n",
    "        print(f\"Game {game_id} JSON data not available yet (last round: {round_no}): \", type(e), e)\n",
    "        continue\n",
    "\n",
    "    result = bball_stats.build_game_stints_stats_df(game_json, game_id)\n",
    "    game_stint_stats_df = result['stint_stats_df']   #  this is basically what we care, the stint stats\n",
    "    game_stints_df = result['stints_df']\n",
    "    game_team1, game_team2 = result['teams']\n",
    "\n",
    "    # Add the game id column to game tables\n",
    "    game_stint_stats_df.insert(0, 'game_id', game_id)\n",
    "    game_stints_df.insert(0, 'game_id', game_id)\n",
    "\n",
    "    # Extract players in the game\n",
    "    players_df = bball_stats.get_players_stats(game_json)\n",
    "    players_df.insert(0, 'game_id', game_id)\n",
    "\n",
    "    # Add tables to collected set of tables, one per game\n",
    "    stint_stats_dfs.append(game_stint_stats_df)\n",
    "    stints_dfs.append(game_stints_df)\n",
    "    players_dfs.append(players_df)\n",
    "\n",
    "    # Next build the record for the game dataframe\n",
    "    # first, extract date of game from HTML page\n",
    "    try:\n",
    "        game_info = tools.get_game_info(game_id)\n",
    "    except:\n",
    "        game_info = { \"venue\" : np.nan, \"date\": np.nan}\n",
    "    print(f\"\\t .... done: {game_team1[0]} ({game_team1[1]}) vs {game_team2[0]} ({game_team2[1]}) on {game_info['date']}\")\n",
    "\n",
    "    games_data.append({\"game_id\": game_id,\n",
    "                        \"date\" : game_info['date'],\n",
    "                        \"round\": round_no,\n",
    "                        \"team1\": game_team1[0],\n",
    "                        \"team2\": game_team2[0],\n",
    "                        \"s1\": game_team1[1],\n",
    "                        \"s2\": game_team2[1],\n",
    "                        \"winner\": 1 if game_team1[1] > game_team2[1] else 2,\n",
    "                        \"venue\" : game_info[\"venue\"]}\n",
    "                      )\n",
    "\n",
    "\n",
    "#################################\n",
    "# All games have been processed, now put all dfs together\n",
    "#################################\n",
    "if len(games_data) == 0:\n",
    "    raise SystemExit(\"No games!\")\n",
    "\n",
    "# First, build a dataframe with all the game data collected\n",
    "games_scrapped_df = pd.DataFrame(games_data)    # games that have been scrapped from web\n",
    "games_df =  games_scrapped_df if saved_games_df is None else pd.concat([saved_games_df, games_scrapped_df])\n",
    "games_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Build players dataframe\n",
    "players_df = pd.concat(players_dfs + ([saved_players_df] if saved_players_df is not None else []))\n",
    "players_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Build stint stats dataframe\n",
    "stint_stats_df = pd.concat(stint_stats_dfs + ([saved_stint_stats_df] if saved_stint_stats_df is not None else []))\n",
    "stint_stats_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Build stints dataframe\n",
    "stints_df = pd.concat(stints_dfs + ([saved_stints_df] if saved_stints_df is not None else []))\n",
    "stints_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Number of total games collected: \", games_df.shape[0])\n",
    "print(\"Number of NEW collected: \", games_df.shape[0] - len(existing_games))\n",
    "print(\"Number of FAILED games (not yet played): \", len(games) - games_df.shape[0])\n",
    "\n",
    "# games_df.sample(min(games_df.shape[0], 5))\n",
    "games_scrapped_df # report all new games scrapped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want we can do some sanity checks, before saving to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtale.show(games_df)\n",
    "# dtale.show(stint_stats_df)\n",
    "# dtale.show(stints_df)\n",
    "# dtale.show(players_df)\n",
    "\n",
    "games_scrapped_df    # show new games scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "print(\"The shape of stats_df is:\", stint_stats_df.shape)\n",
    "stats_cols = list(stint_stats_df.columns[4:-49])\n",
    "print(\"Stats cols:\", stats_cols)\n",
    "\n",
    "# build columns we want to show\n",
    "cols = ['game_id' , 'tno', 'team', 'stint']\n",
    "rnd_cols = random.sample(stats_cols, 8)\n",
    "rnd_cols.extend([f\"{x}_opp\" for x in rnd_cols])\n",
    "cols.extend(rnd_cols)\n",
    "\n",
    "# show some sample of stats computed\n",
    "stint_stats_df[cols].sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that `(ortg, drtg)` (offensive/defensive rate goal) should mirror `(drtg_opp, ortg_opp)` (opponent offensive/defensive rate goal)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ortg, drtg) should mirror (drtg_opp, ortg_opp)\n",
    "stint_stats_df.iloc[4][['game_id' , 'team', 'poss', 'ortg', 'drtg', \"poss_opp\", \"ortg_opp\", \"drtg_opp\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save stats and games to files\n",
    "\n",
    "We now save the full dataframes (stats and games) in various formats: binary (pickle), csv, and Excel.\n",
    "\n",
    "This will allows us to re-load that data later to add more games to it quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# make a backup of existing tables on files\n",
    "for pkl_file in FILES.values():\n",
    "    for ext in ['.csv', '.xlsx', '.pkl']:\n",
    "        file = Path(pkl_file).with_suffix(ext)\n",
    "        if os.path.exists(file):\n",
    "            # print(\"Backup file\", file)\n",
    "            shutil.copy(file, str(file) + \".bak\")\n",
    "\n",
    "# dump stint stats dataframe\n",
    "stint_stats_df.to_pickle(Path(DATA_DIR, \"stint_stats_df\").with_suffix(\".pkl\"))\n",
    "stint_stats_df.to_csv(Path(DATA_DIR, \"stint_stats_df\").with_suffix(\".csv\"), index=False)\n",
    "stint_stats_df.to_excel(Path(DATA_DIR, \"stint_stats_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "# dump stint stats dataframe\n",
    "stints_df.to_pickle(Path(DATA_DIR, \"stints_df\").with_suffix(\".pkl\"))\n",
    "stints_df.to_csv(Path(DATA_DIR, \"stints_df\").with_suffix(\".csv\"), index=False)\n",
    "stints_df.to_excel(Path(DATA_DIR, \"stints_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "# dump game dataframe\n",
    "games_df.to_pickle(Path(DATA_DIR, \"games_df\").with_suffix(\".pkl\"))\n",
    "games_df.to_csv(Path(DATA_DIR, \"games_df\").with_suffix(\".csv\"), index=False)\n",
    "games_df.to_excel(Path(DATA_DIR, \"games_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "# dump players dataframe\n",
    "players_df.to_pickle(Path(DATA_DIR, \"players_df\").with_suffix(\".pkl\"))\n",
    "players_df.to_csv(Path(DATA_DIR, \"players_df\").with_suffix(\".csv\"), index=False)\n",
    "players_df.to_excel(Path(DATA_DIR, \"players_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "now = datetime.datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "print(f\"Finished saving in {DATA_DIR} @ {date_time}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspection & analysis\n",
    "\n",
    "We use [dtale](https://pypi.org/project/dtale/) package for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(stint_stats_df)\n",
    "# dtale.show(stats_df[['tno', 'stint', 'poss', 'ortg', 'drtg', \"poss_opp\", \"ortg_opp\", \"drtg_opp\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Some checks..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a stint lineup has more than 5 players! It could happen:\n",
    "\n",
    "1. Game 2031329, player H. Besson comes out (wrongly?) at 3rd period min 10:00 but he keeps playing and then goes out again at 7:33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stint_stats_df.shape\n",
    "mask = stint_stats_df['lineup'].apply(lambda x: len(x) != 5)\n",
    "stint_stats_df[mask]\n",
    "\n",
    "# stats_df.iloc[941][['game_id', 'lineup']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
