{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyNBL: Basketball Statistic System for Australian NBL\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ssardina/pynbl/HEAD)\n",
    "\n",
    "This notebook **incrementally** builds a set of stat tables from NBL Basketball Games:\n",
    "\n",
    "1. A table of games played, with team names, points, venue, etc.\n",
    "2. A stat table of _stint lineups_ (advance) statistics for each game and each team. A **stint** is a lineup of players who play together in different interval periods across the game. This table will contain the stints for each team from the play-by-play data and compute various statistics for those stints.\n",
    "\n",
    "Tables will be saved in CSV and Excel formats as well as in [Pickle format](https://docs.python.org/3/library/pickle.html) for later recovery as Panda DataFrames.\n",
    "\n",
    "\n",
    "The data comes as a raw JSON file using the game id (e.g., `2087737`):\n",
    "\n",
    "https://fibalivestats.dcd.shared.geniussports.com/data/2087737/data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking __init__.py for nbl\n"
     ]
    }
   ],
   "source": [
    "# Let's first load all required packages...\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dtale\n",
    "\n",
    "from nbl.config import *\n",
    "from nbl import bball_stats, tools\n",
    "\n",
    "\n",
    "# Set folder with data files and Pickle tables saved on disk\n",
    "def get_save_files(dir):\n",
    "    FILES = dict()\n",
    "    FILES['stint_stats'] = Path(dir, \"stint_stats_df\").with_suffix('.pkl')\n",
    "    FILES['stints'] = Path(dir, \"stints_df\").with_suffix('.pkl')\n",
    "    FILES['games'] = Path(dir, \"games_df\").with_suffix('.pkl')\n",
    "    FILES['players'] = Path(dir, \"players_df\").with_suffix('.pkl')\n",
    "\n",
    "    return FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "First, setup the games we want to scrape and compute, as well as the existing data stored in file to append to.\n",
    "\n",
    "**Note:** This should be the only section requiring modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games to scrape (1): [('139002', 0)]\n",
      "Folder to be used: data-23/\n",
      "Reload games? False\n"
     ]
    }
   ],
   "source": [
    "# Games to be computed  - Format: (game id, round number)\n",
    "from games_23 import GAMES\n",
    "\n",
    "# DATA_DIR = 'data-20_21/'\n",
    "# DATA_DIR = 'data-21_22/'\n",
    "# DATA_DIR = 'data-22_23/'\n",
    "DATA_DIR = 'data-23/'\n",
    "games = GAMES\n",
    "\n",
    "games_issues = [('2031329', 0)  # https://github.com/ssardina/pynbl/issues/1\n",
    "         ]\n",
    "# DATA_DIR, games = 'test/', games_issues\n",
    "\n",
    "# Set to True to re-compute from scratch all tables\n",
    "reload = False\n",
    "\n",
    "print(f\"Games to scrape ({len(games)}):\", games)\n",
    "print(\"Folder to be used:\", DATA_DIR)\n",
    "print(\"Reload games?\", reload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute stat and game tables\n",
    "\n",
    "Now, let us run the system that scrapes the games' data, computes stats and game info, and adds them to the initial tables of stats and games.\n",
    "\n",
    "We start by loading all saved previous games, if any, as we want to append to that database (and we don't want to recompute them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recorded dataframes from files\n",
      "Error loading Pickle files:  [Errno 2] No such file or directory: 'data-23/stint_stats_df.pkl'\n",
      "Recovered 0 games:  []\n"
     ]
    }
   ],
   "source": [
    "# Load tables from saved files (if any)\n",
    "saved_stint_stats_df = None\n",
    "saved_stints_df = None\n",
    "saved_games_df = None\n",
    "saved_players_df = None\n",
    "existing_games = []\n",
    "\n",
    "FILES = get_save_files(DATA_DIR)\n",
    "\n",
    "if not reload:\n",
    "    # load the stat dataframe already stored as a file\n",
    "    print(f\"Loading recorded dataframes from files\")\n",
    "    try:\n",
    "        saved_stint_stats_df = pd.read_pickle(FILES['stint_stats'])\n",
    "        saved_stints_df = pd.read_pickle(FILES['stints'])\n",
    "        saved_games_df = pd.read_pickle(FILES['games'])\n",
    "        saved_players_df = pd.read_pickle(FILES['players'])\n",
    "        # collect game ids of all games recovered from file\n",
    "        existing_games = saved_games_df.game_id.unique()\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Error loading Pickle files: \", e)\n",
    "        saved_stint_stats_df = None\n",
    "        saved_stints_df = None\n",
    "        saved_games_df = None\n",
    "        saved_players_df = None\n",
    "        existing_games = []\n",
    "else:\n",
    "    existing_games = []\n",
    "\n",
    "print(f\"Recovered {len(existing_games)} games: \", existing_games)\n",
    "\n",
    "# saved_stats_df['lineup'].apply(lambda x: len(x) > 5)\n",
    "# saved_stats_df.loc[5,'lineup']\n",
    "# saved_stats_df.loc[5]\n",
    "\n",
    "# saved_stint_stats_df.sample(3)\n",
    "# saved_games_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to process games to extract:\n",
    "\n",
    "1. Table of **games**.\n",
    "2. Table of **players** who played in each game with their stats, for each team.\n",
    "3. Table of **stints** in each game for each team.\n",
    "4. Table of **stint stats** in each game for each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing game 139002 (round 0)...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'internationalFirstName'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'internationalFirstName'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/ssardina/GoogleDrive/PROJECTS/basketball/pynbl.git/bball_stats.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ssardina/GoogleDrive/PROJECTS/basketball/pynbl.git/bball_stats.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGame \u001b[39m\u001b[39m{\u001b[39;00mgame_id\u001b[39m}\u001b[39;00m\u001b[39m JSON data not available yet (last round: \u001b[39m\u001b[39m{\u001b[39;00mround_no\u001b[39m}\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(e), e)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ssardina/GoogleDrive/PROJECTS/basketball/pynbl.git/bball_stats.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ssardina/GoogleDrive/PROJECTS/basketball/pynbl.git/bball_stats.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m result \u001b[39m=\u001b[39m bball_stats\u001b[39m.\u001b[39;49mbuild_game_stints_stats_df(game_json, game_id)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ssardina/GoogleDrive/PROJECTS/basketball/pynbl.git/bball_stats.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m game_stint_stats_df \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mstint_stats_df\u001b[39m\u001b[39m'\u001b[39m]   \u001b[39m#  this is basically what we care, the stint stats\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ssardina/GoogleDrive/PROJECTS/basketball/pynbl.git/bball_stats.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m game_stints_df \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mstints_df\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Insync/ssardina@gmail.com/GoogleDrive/PROJECTS/basketball/pynbl.git/nbl/bball_stats.py:197\u001b[0m, in \u001b[0;36mbuild_game_stints_stats_df\u001b[0;34m(game_json, game_id)\u001b[0m\n\u001b[1;32m    194\u001b[0m score_1, score_2 \u001b[39m=\u001b[39m get_team_scores(game_json)\n\u001b[1;32m    196\u001b[0m \u001b[39m# 2. Read game JSON file\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m pbp_df \u001b[39m=\u001b[39m get_pbp_df(game_json)\n\u001b[1;32m    199\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting stint stats for game \u001b[39m\u001b[39m{\u001b[39;00mgame_id\u001b[39m}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{\u001b[39;00mteam_name_1\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mscore_1\u001b[39m}\u001b[39;00m\u001b[39m) vs \u001b[39m\u001b[39m{\u001b[39;00mteam_name_2\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mscore_2\u001b[39m}\u001b[39;00m\u001b[39m)] - No of PBP: \u001b[39m\u001b[39m{\u001b[39;00mpbp_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[39m# print(f\"====> Game {team_name_1} ({team_short_name_1}) vs {team_name_2} ({team_short_name_2})\")\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39m# print(f\"Play-by-play df for game {game_id}: {pbp_df.shape}\")\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[39m# 3. Compute stints (dictionaries) for each team\u001b[39;00m\n",
      "File \u001b[0;32m~/Insync/ssardina@gmail.com/GoogleDrive/PROJECTS/basketball/pynbl.git/nbl/bball_stats.py:113\u001b[0m, in \u001b[0;36mget_pbp_df\u001b[0;34m(game_json)\u001b[0m\n\u001b[1;32m    110\u001b[0m pbp_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(game_json, record_path \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpbp\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[39m# standarize player's name to be used all over\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m pbp_df[\u001b[39m'\u001b[39m\u001b[39mplayer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pbp_df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: tools\u001b[39m.\u001b[39;49mbuild_player_names(x), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    114\u001b[0m pbp_df\u001b[39m.\u001b[39mloc[pbp_df[\u001b[39m'\u001b[39m\u001b[39mperiodType\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOVERTIME\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mperiod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pbp_df[\u001b[39m'\u001b[39m\u001b[39mperiod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m# make overtime periods start at 5\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# keep columns 1 to 17, drop all player info\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# This is what is kept ['clock', 's1', 's2', 'lead', 'tno', 'period', 'periodType', 'pno',\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m#    'player', 'success', 'actionType', 'actionNumber', 'previousAction',\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m#    'qualifier', 'subType', 'scoring']\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# pbp_df = pbp_df.iloc[:, 1:17]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:9565\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9554\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9556\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9557\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9558\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9563\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9564\u001b[0m )\n\u001b[0;32m-> 9565\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 746\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 873\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    875\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    888\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    890\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    891\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    892\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    893\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Insync/ssardina@gmail.com/GoogleDrive/PROJECTS/basketball/pynbl.git/nbl/bball_stats.py:113\u001b[0m, in \u001b[0;36mget_pbp_df.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    110\u001b[0m pbp_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(game_json, record_path \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpbp\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[39m# standarize player's name to be used all over\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m pbp_df[\u001b[39m'\u001b[39m\u001b[39mplayer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pbp_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: tools\u001b[39m.\u001b[39;49mbuild_player_names(x), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    114\u001b[0m pbp_df\u001b[39m.\u001b[39mloc[pbp_df[\u001b[39m'\u001b[39m\u001b[39mperiodType\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOVERTIME\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mperiod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pbp_df[\u001b[39m'\u001b[39m\u001b[39mperiod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m# make overtime periods start at 5\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# keep columns 1 to 17, drop all player info\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# This is what is kept ['clock', 's1', 's2', 'lead', 'tno', 'period', 'periodType', 'pno',\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m#    'player', 'success', 'actionType', 'actionNumber', 'previousAction',\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m#    'qualifier', 'subType', 'scoring']\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# pbp_df = pbp_df.iloc[:, 1:17]\u001b[39;00m\n",
      "File \u001b[0;32m~/Insync/ssardina@gmail.com/GoogleDrive/PROJECTS/basketball/pynbl.git/nbl/tools.py:137\u001b[0m, in \u001b[0;36mbuild_player_names\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m\"\"\"Output the standarized name of a player\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m    pd.Series | pd.DataFrame : a series with standarized names of each player\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, pd\u001b[39m.\u001b[39mSeries):\n\u001b[1;32m    136\u001b[0m \u001b[39m# return f\"{x['internationalFirstNameInitial']}. {x['internationalFamilyName']}\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mx[\u001b[39m'\u001b[39m\u001b[39minternationalFirstName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mx[\u001b[39m'\u001b[39m\u001b[39minternationalFamilyName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[1;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mx[\u001b[39m'\u001b[39m\u001b[39minternationalFirstName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mx[\u001b[39m'\u001b[39m\u001b[39minternationalFamilyName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'internationalFirstName'"
     ]
    }
   ],
   "source": [
    "# collect here set of stat dfs and game info, one per game\n",
    "#   then, we will put them together into different dataframes\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "\n",
    "stint_stats_dfs = []\n",
    "stints_dfs = []\n",
    "players_dfs = []\n",
    "games_data = []\n",
    "\n",
    "# sort games by rounds (second component of tuple) and get min/max rounds\n",
    "games.sort(key = lambda x: x[1])\n",
    "first_round = games[0][1]\n",
    "last_round = games[-1][1]\n",
    "\n",
    "# Build data for each game, we'll put them together after....\n",
    "for game in games:\n",
    "    # game is beyond the last round available, stop processing..\n",
    "    if game[1] > last_round:\n",
    "        break\n",
    "\n",
    "    # get game_id and round no (if available)\n",
    "    if isinstance(game, tuple):\n",
    "        game_id, round_no = game\n",
    "    else:\n",
    "        game_id = game\n",
    "        round_no = np.nan # no round info available\n",
    "\n",
    "    # don't scrape game data if already loaded from file, skip it\n",
    "    if game_id in existing_games:\n",
    "        print(f\"Game {game_id} was already saved on file; no scrapping...\")\n",
    "        continue\n",
    "\n",
    "    ##################################################################\n",
    "    # !!! MAIN STEP: scrape and compute the actual stats for the game\n",
    "    ##################################################################\n",
    "    print(f\"Computing game {game_id} (round {round_no})...\")\n",
    "\n",
    "    # 1. Read game JSON file\n",
    "    try:\n",
    "        game_json = tools.get_json_data(game_id, dir=DATA_DIR)\n",
    "    except (HTTPError, ValueError) as e:\n",
    "        last_round = round_no    # this is the last round to be processed!\n",
    "        print(f\"Game {game_id} JSON data not available yet (last round: {round_no}): \", type(e), e)\n",
    "        continue\n",
    "\n",
    "    result = bball_stats.build_game_stints_stats_df(game_json, game_id)\n",
    "    game_stint_stats_df = result['stint_stats_df']   #  this is basically what we care, the stint stats\n",
    "    game_stints_df = result['stints_df']\n",
    "    game_team1, game_team2 = result['teams']\n",
    "\n",
    "    # Add the game id column to game tables\n",
    "    game_stint_stats_df.insert(0, 'game_id', game_id)\n",
    "    game_stints_df.insert(0, 'game_id', game_id)\n",
    "\n",
    "    # Extract players in the game\n",
    "    players_df = bball_stats.get_players_stats(game_json)\n",
    "    players_df.insert(0, 'game_id', game_id)\n",
    "\n",
    "    # Add tables to collected set of tables, one per game\n",
    "    stint_stats_dfs.append(game_stint_stats_df)\n",
    "    stints_dfs.append(game_stints_df)\n",
    "    players_dfs.append(players_df)\n",
    "\n",
    "    # Next build the record for the game dataframe\n",
    "    # first, extract date of game from HTML page\n",
    "    try:\n",
    "        game_info = tools.get_game_info(game_id)\n",
    "    except:\n",
    "        game_info = { \"venue\" : np.nan, \"date\": np.nan}\n",
    "    print(f\"\\t .... done: {game_team1[0]} ({game_team1[1]}) vs {game_team2[0]} ({game_team2[1]}) on {game_info['date']}\")\n",
    "\n",
    "    games_data.append({\"game_id\": game_id,\n",
    "                        \"date\" : game_info['date'],\n",
    "                        \"round\": round_no,\n",
    "                        \"team1\": game_team1[0],\n",
    "                        \"team2\": game_team2[0],\n",
    "                        \"s1\": game_team1[1],\n",
    "                        \"s2\": game_team2[1],\n",
    "                        \"winner\": 1 if game_team1[1] > game_team2[1] else 2,\n",
    "                        \"venue\" : game_info[\"venue\"]}\n",
    "                      )\n",
    "\n",
    "\n",
    "#################################\n",
    "# All games have been processed, now put all dfs together\n",
    "#################################\n",
    "if len(games_data) == 0:\n",
    "    raise SystemExit(\"No games!\")\n",
    "\n",
    "# First, build a dataframe with all the game data collected\n",
    "games_scrapped_df = pd.DataFrame(games_data)    # games that have been scrapped from web\n",
    "games_df =  games_scrapped_df if saved_games_df is None else pd.concat([saved_games_df, games_scrapped_df])\n",
    "games_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Build players dataframe\n",
    "players_df = pd.concat(players_dfs + ([saved_players_df] if saved_players_df is not None else []))\n",
    "players_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Build stint stats dataframe\n",
    "stint_stats_df = pd.concat(stint_stats_dfs + ([saved_stint_stats_df] if saved_stint_stats_df is not None else []))\n",
    "stint_stats_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Build stints dataframe\n",
    "stints_df = pd.concat(stints_dfs + ([saved_stints_df] if saved_stints_df is not None else []))\n",
    "stints_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Number of total games collected: \", games_df.shape[0])\n",
    "print(\"Number of NEW collected: \", games_df.shape[0] - len(existing_games))\n",
    "print(\"Number of FAILED games (not yet played): \", len(games) - games_df.shape[0])\n",
    "\n",
    "# games_df.sample(min(games_df.shape[0], 5))\n",
    "games_scrapped_df # report all new games scrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want we can do some sanity checks, before saving to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtale.show(games_df)\n",
    "# dtale.show(stint_stats_df)\n",
    "# dtale.show(stints_df)\n",
    "# dtale.show(players_df)\n",
    "\n",
    "games_scrapped_df    # show new games scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "print(\"The shape of stats_df is:\", stint_stats_df.shape)\n",
    "stats_cols = list(stint_stats_df.columns[4:-49])\n",
    "print(\"Stats cols:\", stats_cols)\n",
    "\n",
    "# build columns we want to show\n",
    "cols = ['game_id' , 'tno', 'team', 'stint']\n",
    "rnd_cols = random.sample(stats_cols, 8)\n",
    "rnd_cols.extend([f\"{x}_opp\" for x in rnd_cols])\n",
    "cols.extend(rnd_cols)\n",
    "\n",
    "# show some sample of stats computed\n",
    "stint_stats_df[cols].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that `(ortg, drtg)` (offensive/defensive rate goal) should mirror `(drtg_opp, ortg_opp)` (opponent offensive/defensive rate goal)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ortg, drtg) should mirror (drtg_opp, ortg_opp)\n",
    "stint_stats_df.iloc[4][['game_id' , 'team', 'poss', 'ortg', 'drtg', \"poss_opp\", \"ortg_opp\", \"drtg_opp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save stats and games to files\n",
    "\n",
    "We now save the full dataframes (stats and games) in various formats: binary (pickle), csv, and Excel.\n",
    "\n",
    "This will allows us to re-load that data later to add more games to it quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# make a backup of existing tables on files\n",
    "for pkl_file in FILES.values():\n",
    "    for ext in ['.csv', '.xlsx', '.pkl']:\n",
    "        file = Path(pkl_file).with_suffix(ext)\n",
    "        if os.path.exists(file):\n",
    "            # print(\"Backup file\", file)\n",
    "            shutil.copy(file, str(file) + \".bak\")\n",
    "\n",
    "# dump stint stats dataframe\n",
    "stint_stats_df.to_pickle(Path(DATA_DIR, \"stint_stats_df\").with_suffix(\".pkl\"))\n",
    "stint_stats_df.to_csv(Path(DATA_DIR, \"stint_stats_df\").with_suffix(\".csv\"), index=False)\n",
    "stint_stats_df.to_excel(Path(DATA_DIR, \"stint_stats_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "# dump stint stats dataframe\n",
    "stints_df.to_pickle(Path(DATA_DIR, \"stints_df\").with_suffix(\".pkl\"))\n",
    "stints_df.to_csv(Path(DATA_DIR, \"stints_df\").with_suffix(\".csv\"), index=False)\n",
    "stints_df.to_excel(Path(DATA_DIR, \"stints_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "# dump game dataframe\n",
    "games_df.to_pickle(Path(DATA_DIR, \"games_df\").with_suffix(\".pkl\"))\n",
    "games_df.to_csv(Path(DATA_DIR, \"games_df\").with_suffix(\".csv\"), index=False)\n",
    "games_df.to_excel(Path(DATA_DIR, \"games_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "# dump players dataframe\n",
    "players_df.to_pickle(Path(DATA_DIR, \"players_df\").with_suffix(\".pkl\"))\n",
    "players_df.to_csv(Path(DATA_DIR, \"players_df\").with_suffix(\".csv\"), index=False)\n",
    "players_df.to_excel(Path(DATA_DIR, \"players_df\").with_suffix(\".xlsx\"), index=False)\n",
    "\n",
    "now = datetime.datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "print(f\"Finished saving in {DATA_DIR} @ {date_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspection & analysis\n",
    "\n",
    "We use [dtale](https://pypi.org/project/dtale/) package for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(stint_stats_df)\n",
    "# dtale.show(stats_df[['tno', 'stint', 'poss', 'ortg', 'drtg', \"poss_opp\", \"ortg_opp\", \"drtg_opp\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Some checks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a stint lineup has more than 5 players! It could happen:\n",
    "\n",
    "1. Game 2031329, player H. Besson comes out (wrongly?) at 3rd period min 10:00 but he keeps playing and then goes out again at 7:33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stint_stats_df.shape\n",
    "mask = stint_stats_df['lineup'].apply(lambda x: len(x) != 5)\n",
    "stint_stats_df[mask]\n",
    "\n",
    "# stats_df.iloc[941][['game_id', 'lineup']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
